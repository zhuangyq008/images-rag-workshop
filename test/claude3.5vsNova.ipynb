{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from botocore.exceptions import ClientError\n",
    "from os import listdir, walk\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# image to base64\n",
    "def image_to_base64(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        # 创建一个字节流对象\n",
    "        buffered = BytesIO()\n",
    "        # 将图片保存到字节流中，并指定格式 (例如 'JPEG', 'PNG')\n",
    "        img.save(buffered, format=img.format)\n",
    "        # 获取字节数据并进行 Base64 编码\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        return img_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(base64_image_data,width,height):\n",
    "        try:\n",
    "            image_data = base64.b64decode(base64_image_data)\n",
    "            # 将二进制数据转换为 Pillow 支持的 Image 对象\n",
    "            image = Image.open(BytesIO(image_data))\n",
    "            # 调整图片大小到 320x320\n",
    "            resized_image = image.resize((width, height))\n",
    "\n",
    "            # 将调整后的图片直接转换为 Base64 编码\n",
    "            buffer = BytesIO()\n",
    "            resized_image.save(buffer, format=image.format)  # 使用原始格式保存到内存\n",
    "            resized_base64_data = base64.b64encode(buffer.getvalue()).decode()  # 转为 Base64 字符串\n",
    "            return resized_base64_data\n",
    "        except Exception as e:\n",
    "            raise HTTPException(status_code=500, detail=f\"Error in resize image: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nova generate description test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描述信息生成函数\n",
    "def enrich_image_desc(image_base64):\n",
    "    client = boto3.client(\n",
    "        \"bedrock-runtime\"\n",
    "    )\n",
    "\n",
    "    # Set the model ID, e.g., Titan Text Premier.\n",
    "    # anthropic.claude-3-haiku-20240307-v1:0\n",
    "    # anthropic.claude-3-5-sonnet-20240620-v1:0\n",
    "    model_id = 'amazon.nova-pro-v1:0'\n",
    "\n",
    "    # Start a conversation with the user message.\n",
    "    user_message = \"\"\"\n",
    "        You will be analyzing an image and extracting its key features, including tags, and providing a brief summary of the image content.\n",
    "\n",
    "        First, carefully examine the image provided in {$IMAGE}.\n",
    "\n",
    "        Then, in Markdown format, provide the following:\n",
    "\n",
    "        1. **Tags**: List the key tags that describe the main elements and subjects in the image.\n",
    "        2. **Summary**: Write a concise 1-2 sentence summary describing the overall content and meaning of the image.\n",
    "\n",
    "        Format your response as follows:\n",
    "\n",
    "        # Image Analysis\n",
    "\n",
    "        ## Tags\n",
    "        - Tag 1\n",
    "        - Tag 2\n",
    "        - Tag 3\n",
    "\n",
    "        ## Summary\n",
    "        A brief 1-2 sentence summary of the image content.\n",
    "\n",
    "        Provide your response within <result> tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_resize(image_base64,320,320)\n",
    "\n",
    "\n",
    "    if model_id=='anthropic.claude-3-5-sonnet-20240620-v1:0':\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 5000,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"image\",\n",
    "                                \"source\": {\n",
    "                                    \"type\": \"base64\",\n",
    "                                    \"media_type\": \"image/jpeg\",\n",
    "                                    \"data\": image_base64,\n",
    "                                },\n",
    "                            },\n",
    "                            {\"type\": \"text\", \"text\": user_message},\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                \n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        print(\"in\")\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"schemaVersion\": \"messages-v1\",\n",
    "                \"inferenceConfig\": {\"max_new_tokens\": 5000},\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"image\": {\n",
    "                                    \"format\": \"jpg\",\n",
    "                                    \"source\": {\"bytes\": image_base64},\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                \"text\": user_message\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    try:\n",
    "        # Send the message to the model, using a basic inference configuration.\n",
    "        response = client.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=body\n",
    "        )\n",
    "\n",
    "        # Extract and print the response text.\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        print(response_body)\n",
    "        return response_body\n",
    "\n",
    "    except (ClientError, Exception) as e:\n",
    "        print(str(e))\n",
    "        # return(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        # exit(1)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "{'output': {'message': {'content': [{'text': '<result>\\n\\n# Image Analysis\\n\\n## Tags\\n- Butterfly\\n- Mouse pad\\n- Computer mouse\\n- Desk\\n- Design\\n\\n## Summary\\nAn image showcasing a wooden desk with a computer monitor, keyboard, and a mouse pad featuring a butterfly design. A white computer mouse is placed on the mouse pad.\\n\\n</result>'}], 'role': 'assistant'}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 1472, 'outputTokens': 58, 'totalTokens': 1530, 'cacheReadInputTokenCount': None, 'cacheWriteInputTokenCount': None}}\n"
     ]
    }
   ],
   "source": [
    "img_base64 = image_to_base64(\"/Users/fangyili/Downloads/搜图10.19/元素图相同，款式不同/期望搜索图一.jpg\")\n",
    "img_base64 = image_resize(img_base64,320,320)\n",
    "response_body = enrich_image_desc(img_base64)\n",
    "description = response_body['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '7a8e4a61-8f83-40c6-bd58-bb3df5a761a3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 04 Dec 2024 12:29:55 GMT', 'content-type': 'application/json', 'content-length': '12783', 'connection': 'keep-alive', 'x-amzn-requestid': '7a8e4a61-8f83-40c6-bd58-bb3df5a761a3', 'x-amzn-bedrock-invocation-latency': '89', 'x-amzn-bedrock-input-token-count': '0'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0x10b508700>}\n",
      "0.02035558\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "description = response_body['output']['message']['content'][0]['text']\n",
    "embedding_body = json.dumps({\n",
    "    # \"inputText\": description,\n",
    "    \"inputImage\": img_base64,\n",
    "    \"embeddingConfig\": {\n",
    "        \"outputEmbeddingLength\": 1024\n",
    "    }\n",
    "})\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    body=embedding_body,\n",
    "    modelId='amazon.titan-embed-image-v1',\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "print(response)\n",
    "embedding_json = json.loads(response['body'].read().decode('utf-8'))\n",
    "print(embedding_json[\"embedding\"][0])\n",
    "print(len(embedding_json[\"embedding\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test nova rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'message': {'content': [{'text': '[\\n  {\\n    \"imageIndexNo\": \"6\",\\n    \"reason\": \"The query image on the left shows a leopard pattern, which closely matches the pattern on the phone case in cell 6 on the right grid. The leopard spots in both images are similar in size, shape, and distribution, making cell 6 the best match for the user\\'s query.\"\\n  }\\n]'}], 'role': 'assistant'}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 1572, 'outputTokens': 73, 'totalTokens': 1645, 'cacheReadInputTokenCount': None, 'cacheWriteInputTokenCount': None}}\n",
      "[\n",
      "  {\n",
      "    \"imageIndexNo\": \"6\",\n",
      "    \"reason\": \"The query image on the left shows a leopard pattern, which closely matches the pattern on the phone case in cell 6 on the right grid. The leopard spots in both images are similar in size, shape, and distribution, making cell 6 the best match for the user's query.\"\n",
      "  }\n",
      "]\n",
      "[{'imageIndexNo': '6', 'reason': \"The query image on the left shows a leopard pattern, which closely matches the pattern on the phone case in cell 6 on the right grid. The leopard spots in both images are similar in size, shape, and distribution, making cell 6 the best match for the user's query.\"}]\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "query_text = 'find a phone case with similar pattern'\n",
    "prompt = f\"\"\"You are an AI assistant tasked with identifying the cell in an image that best matches a user's query. The image shows two parts: on the left is the query image, and on the right is a grid of numbered cells.\n",
    "\n",
    "Your goal is to review the user's query ({query_text}) and both images, then identify the cell from the right grid that best matches the query image and text. You should provide your response in JSON format, with the following structure:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"imageIndexNo\": \"the index number of the matching cell\",\n",
    "    \"reason\": \"a brief explanation of why this cell is the best match\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "To accomplish this task:\n",
    "\n",
    "1. Carefully review the user's query ({query_text}) and the query image on the left.\n",
    "2. Examine the grid on the right and identify the cell that best matches based on visual features and the query.\n",
    "3. Determine the index number of the matching cell.\n",
    "4. Write a brief explanation of why this cell is the best match.\n",
    "5. Format your response in the JSON structure specified above.\n",
    "\n",
    "Be as specific and accurate as possible in your response. If you are unable to identify a clear match, explain why in your response.\"\"\"\n",
    "image_base64 = image_to_base64(\"/Users/fangyili/Downloads/Picture1.png\")\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"schemaVersion\": \"messages-v1\",\n",
    "        \"inferenceConfig\": {\"max_new_tokens\": 1024},\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"format\": \"png\",\n",
    "                            \"source\": {\"bytes\": image_base64},\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId='amazon.nova-pro-v1:0',\n",
    "    body=body\n",
    ")\n",
    "\n",
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body)\n",
    "response_body = response_body['output']['message']['content'][0]['text']\n",
    "print(response_body)\n",
    "matches = json.loads(response_body)\n",
    "print(matches)\n",
    "matched_indices = [int(match['imageIndexNo']) for match in matches]\n",
    "print(matched_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'msg_bdrk_01M3rQFtM4kV5t5eTeqE5LXc', 'type': 'message', 'role': 'assistant', 'model': 'claude-3-5-sonnet-20240620', 'content': [{'type': 'text', 'text': 'Based on the query to find a phone case with a similar pattern to the image on the left, which appears to show a leopard, I\\'ve analyzed the grid of phone cases on the right. Here\\'s my response in the requested JSON format:\\n\\n[\\n  {\\n    \"imageIndexNo\": \"7\",\\n    \"reason\": \"Cell 7 shows a phone case with a blue leopard print pattern, which is the closest match to the leopard pattern in the query image. While the colors are different (blue instead of the natural leopard colors), the distinctive spotted pattern of a leopard\\'s coat is clearly represented, making this the best match for the requested similar pattern.\"\\n  }\\n]'}], 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 509, 'output_tokens': 150}}\n"
     ]
    }
   ],
   "source": [
    "query_text = 'find a phone case with similar pattern'\n",
    "prompt = f\"\"\"You are an AI assistant tasked with identifying the cell in an image that best matches a user's query. The image shows two parts: on the left is the query image, and on the right is a grid of numbered cells.\n",
    "\n",
    "Your goal is to review the user's query ({query_text}) and both images, then identify the cell from the right grid that best matches the query image and text. You should provide your response in JSON format, with the following structure:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"imageIndexNo\": \"the index number of the matching cell\",\n",
    "    \"reason\": \"a brief explanation of why this cell is the best match\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "To accomplish this task:\n",
    "\n",
    "1. Carefully review the user's query ({query_text}) and the query image on the left.\n",
    "2. Examine the grid on the right and identify the cell that best matches based on visual features and the query.\n",
    "3. Determine the index number of the matching cell.\n",
    "4. Write a brief explanation of why this cell is the best match.\n",
    "5. Format your response in the JSON structure specified above.\n",
    "\n",
    "Be as specific and accurate as possible in your response. If you are unable to identify a clear match, explain why in your response.\"\"\"\n",
    "image_base64 = image_to_base64(\"/Users/fangyili/Downloads/Picture1.png\")\n",
    "body = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/png\",\n",
    "                        \"data\": image_base64\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "    body=json.dumps(body)\n",
    ")\n",
    "        \n",
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the query to find a phone case with a similar pattern to the image on the left, which appears to show a leopard, I\\'ve analyzed the grid of phone cases on the right. Here\\'s my response in the requested JSON format:\\n\\n[\\n  {\\n    \"imageIndexNo\": \"7\",\\n    \"reason\": \"Cell 7 shows a phone case with a blue leopard print pattern, which is the closest match to the leopard pattern in the query image. While the colors are different (blue instead of the natural leopard colors), the distinctive spotted pattern of a leopard\\'s coat is clearly represented, making this the best match for the requested similar pattern.\"\\n  }\\n]'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = response_body['content'][0]['text']\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Rerank items based on Claude's response\u001b[39;00m\n\u001b[1;32m      3\u001b[0m reranked_items \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "matches = json.loads(response)\n",
    "matched_indices = [int(match['imageIndexNo']) for match in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test batch upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import base64\n",
    "import datetime\n",
    "import uuid\n",
    "import logging\n",
    "import jsonlines\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "paginator = s3_client.get_paginator('list_objects_v2')\n",
    "first = True\n",
    "next_token = None\n",
    "# Initialization: Initialize a bedrock client\n",
    "client = boto3.client('bedrock')\n",
    "# # Initialization: Create S3 directory\n",
    "# s3_client.put_object(\n",
    "#     Bucket='imagebucket-442042528912-us-east-1',\n",
    "#     Key='INVOCATION-INPUT-NO-IMAGE/'\n",
    "# )\n",
    "# s3_client.put_object(\n",
    "#     Bucket='imagebucket-442042528912-us-east-1',\n",
    "#     Key='INVOCATION-OUTPUT-NO-IMAGE/'\n",
    "# )\n",
    "# Initialization: Invocation job configuration\n",
    "discriptionGeneratorInputDataConfig=({\n",
    "    \"s3InputDataConfig\": {\n",
    "        \"s3Uri\": f\"s3://imagebucket-442042528912-us-east-1/IONVOCATION-INPUT-NO-IMAGE/descn-input.jsonl\"\n",
    "    }\n",
    "})\n",
    "embeddingGeneratorInputDataConfig=({\n",
    "    \"s3InputDataConfig\": {\n",
    "        \"s3Uri\": f\"s3://imagebucket-442042528912-us-east-1/IONVOCATION-INPUT-NO-IMAGE/embedding-input.jsonl\"\n",
    "    }\n",
    "})\n",
    "discriptionGeneratorOutputDataConfig=({\n",
    "    \"s3OutputDataConfig\": {\n",
    "        \"s3Uri\": f\"s3://imagebucket-442042528912-us-east-1/INVOCATION-OUTPUT-NO-IMAGE/{str(uuid.uuid4())}-descn/\"\n",
    "    }\n",
    "})\n",
    "embeddingGeneratorOutputDataConfig=({\n",
    "    \"s3OutputDataConfig\": {\n",
    "        \"s3Uri\": f\"s3://imagebucket-442042528912-us-east-1/INVOCATION-OUTPUT-NO-IMAGE/{str(uuid.uuid4())}-embedding/\"\n",
    "    }\n",
    "})\n",
    "# iterate all uploaded objects\n",
    "while first or next_token:\n",
    "    # Create a PageIterator from the Paginator\n",
    "    page_iterator = paginator.paginate(\n",
    "        Bucket='imagebucket-442042528912-us-east-1',\n",
    "        Prefix='images',\n",
    "        PaginationConfig={'PageSize':10,'StartingToken':next_token}\n",
    "    )\n",
    "    for page in page_iterator:\n",
    "        # one upload batch\n",
    "        documents = []\n",
    "        descn_gen_batch_inference_data = []\n",
    "        embedding_gen_batch_inference_data = []\n",
    "        for obj in page['Contents']:\n",
    "            # Get image base64\n",
    "            s3_key = obj['Key']\n",
    "            response = s3_client.get_object(Bucket='imagebucket-442042528912-us-east-1',Key=s3_key)\n",
    "            streaming_body = response.get(\"Body\").read()\n",
    "            image_base64 = base64.b64encode(streaming_body).decode('utf-8')\n",
    "            image_id = str(uuid.uuid4())\n",
    "            description = ''\n",
    "            # Construct description generation payload\n",
    "            descn_gen_payload = {\n",
    "                \"recordId\": str(uuid.uuid4()), \n",
    "                \"modelInput\": {\n",
    "                    \"schemaVersion\": \"messages-v1\",\n",
    "                    \"inferenceConfig\": {\"max_new_tokens\": 5000},\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"image\": {\n",
    "                                        \"format\": \"jpg\",\n",
    "                                        \"source\": {\"bytes\": image_base64},\n",
    "                                    }\n",
    "                                },\n",
    "                                {\n",
    "                                    \"text\": \"Generate description for the image\"\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            descn_gen_batch_inference_data.append(descn_gen_payload)\n",
    "            # Construct embedding generation payload\n",
    "            embedding_gen_payload = {\n",
    "                \"recordId\": str(uuid.uuid4()),\n",
    "                \"modelInput\":{\n",
    "                    \"inputText\": '',\n",
    "                    \"inputImage\": image_base64,\n",
    "                    \"embeddingConfig\": {\n",
    "                        \"outputEmbeddingLength\": 1024\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            embedding_gen_batch_inference_data.append(embedding_gen_payload)\n",
    "            # Construct document\n",
    "            dt = datetime.datetime.now().isoformat()\n",
    "            document = {\n",
    "                'id': image_id,\n",
    "                'description': description,\n",
    "                'embedding': '',\n",
    "                'createtime': dt,\n",
    "                'image_path': s3_key\n",
    "            }\n",
    "            documents.append(document)\n",
    "        # bulk upload\n",
    "        # Invocation job to generate description\n",
    "        with jsonlines.open('descn-input.jsonl', 'w') as writer:\n",
    "            writer.write_all(descn_gen_batch_inference_data)\n",
    "        s3_client.upload_file('descn-input.jsonl', 'imagebucket-442042528912-us-east-1', 'IONVOCATION-INPUT-NO-IMAGE/descn-input.jsonl')\n",
    "        descn_gen_response = client.create_model_invocation_job(\n",
    "            roleArn='arn:aws:iam::442042528912:role/bedrockBatchJobTestRole',\n",
    "            modelId='amazon.nova-pro-v1:0',\n",
    "            jobName=\"generate-description-batch-job\",\n",
    "            inputDataConfig=discriptionGeneratorInputDataConfig,\n",
    "            outputDataConfig=discriptionGeneratorOutputDataConfig\n",
    "        )\n",
    "        # Invocation job to generate embedding\n",
    "        with jsonlines.open('embedding-input.jsonl', 'w') as writer:\n",
    "            writer.write_all(embedding_gen_batch_inference_data)\n",
    "        s3_client.upload_file('embedding-input.jsonl', 'imagebucket-442042528912-us-east-1', 'IONVOCATION-INPUT-NO-IMAGE/embedding-input.jsonl')\n",
    "        embedding_gen_response = client.create_model_invocation_job(\n",
    "            roleArn='arn:aws:iam::442042528912:role/bedrockBatchJobTestRole',\n",
    "            modelId='amazon.titan-embed-image-v1',\n",
    "            jobName=\"generate-embedding-batch-job\",\n",
    "            inputDataConfig=embeddingGeneratorInputDataConfig,\n",
    "            outputDataConfig=embeddingGeneratorOutputDataConfig\n",
    "        )\n",
    "        break\n",
    "    break\n",
    "        # print(page['Contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35.49\n"
     ]
    }
   ],
   "source": [
    "print(boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'fbb72755-948b-4187-ac4f-485657f8f719',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sun, 08 Dec 2024 11:48:18 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1894',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'fbb72755-948b-4187-ac4f-485657f8f719'},\n",
       "  'RetryAttempts': 0},\n",
       " 'invocationJobSummaries': [{'jobArn': 'arn:aws:bedrock:us-east-1:442042528912:model-invocation-job/d2bneg2cnyvd',\n",
       "   'jobName': 'generate-embedding-batch-job',\n",
       "   'modelId': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0',\n",
       "   'roleArn': 'arn:aws:iam::442042528912:role/bedrockBatchJobTestRole',\n",
       "   'status': 'Validating',\n",
       "   'submitTime': datetime.datetime(2024, 12, 8, 11, 46, 14, 809000, tzinfo=tzutc()),\n",
       "   'lastModifiedTime': datetime.datetime(2024, 12, 8, 11, 46, 58, 543000, tzinfo=tzutc()),\n",
       "   'inputDataConfig': {'s3InputDataConfig': {'s3Uri': 's3://imagebucket-442042528912-us-east-1/IONVOCATION-INPUT-NO-IMAGE/embedding-input.jsonl',\n",
       "     's3BucketOwner': '442042528912'}},\n",
       "   'outputDataConfig': {'s3OutputDataConfig': {'s3Uri': 's3://imagebucket-442042528912-us-east-1/INVOCATION-OUTPUT-NO-IMAGE/ecc5b0e9-09e9-4365-b8a4-fc54bc29acf8-embedding/',\n",
       "     's3BucketOwner': '442042528912'}},\n",
       "   'timeoutDurationInHours': 24},\n",
       "  {'jobArn': 'arn:aws:bedrock:us-east-1:442042528912:model-invocation-job/obvnym8ynkxl',\n",
       "   'jobName': 'generate-description-batch-job',\n",
       "   'modelId': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0',\n",
       "   'roleArn': 'arn:aws:iam::442042528912:role/bedrockBatchJobTestRole',\n",
       "   'status': 'Validating',\n",
       "   'submitTime': datetime.datetime(2024, 12, 8, 11, 46, 11, 487000, tzinfo=tzutc()),\n",
       "   'lastModifiedTime': datetime.datetime(2024, 12, 8, 11, 46, 58, 5000, tzinfo=tzutc()),\n",
       "   'inputDataConfig': {'s3InputDataConfig': {'s3Uri': 's3://imagebucket-442042528912-us-east-1/IONVOCATION-INPUT-NO-IMAGE/descn-input.jsonl',\n",
       "     's3BucketOwner': '442042528912'}},\n",
       "   'outputDataConfig': {'s3OutputDataConfig': {'s3Uri': 's3://imagebucket-442042528912-us-east-1/INVOCATION-OUTPUT-NO-IMAGE/9dcc8502-3880-44f6-85ee-291f6df2e9a3-descn/',\n",
       "     's3BucketOwner': '442042528912'}},\n",
       "   'timeoutDurationInHours': 24}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_model_invocation_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Failed'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_model_invocation_job(jobIdentifier='arn:aws:bedrock:us-east-1:442042528912:model-invocation-job/d2bneg2cnyvd')['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f1fb4612-db12-44a3-b988-30715d912e43',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sun, 08 Dec 2024 11:50:23 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1102',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'f1fb4612-db12-44a3-b988-30715d912e43'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:442042528912:model-invocation-job/d2bneg2cnyvd',\n",
       " 'jobName': 'generate-embedding-batch-job',\n",
       " 'modelId': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0',\n",
       " 'clientRequestToken': '81cfb034-ac93-48bd-969d-d112dfc33ad5',\n",
       " 'roleArn': 'arn:aws:iam::442042528912:role/bedrockBatchJobTestRole',\n",
       " 'status': 'Failed',\n",
       " 'message': 'Batch job arn:aws:bedrock:us-east-1:442042528912:model-invocation-job/d2bneg2cnyvd contains less records (10) than the required minimum of: 100',\n",
       " 'submitTime': datetime.datetime(2024, 12, 8, 11, 46, 14, 809000, tzinfo=tzutc()),\n",
       " 'lastModifiedTime': datetime.datetime(2024, 12, 8, 11, 50, 1, 423000, tzinfo=tzutc()),\n",
       " 'inputDataConfig': {'s3InputDataConfig': {'s3Uri': 's3://imagebucket-442042528912-us-east-1/IONVOCATION-INPUT-NO-IMAGE/embedding-input.jsonl',\n",
       "   's3BucketOwner': '442042528912'}},\n",
       " 'outputDataConfig': {'s3OutputDataConfig': {'s3Uri': 's3://imagebucket-442042528912-us-east-1/INVOCATION-OUTPUT-NO-IMAGE/ecc5b0e9-09e9-4365-b8a4-fc54bc29acf8-embedding/',\n",
       "   's3BucketOwner': '442042528912'}},\n",
       " 'timeoutDurationInHours': 24}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_model_invocation_job(jobIdentifier='arn:aws:bedrock:us-east-1:442042528912:model-invocation-job/d2bneg2cnyvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
